# mu-bde-logging

Provide out-of-the-box automatic logging of your running docker containers, and make the data available on ElasticSearch + Kibana for further analysis and visualization.

## Architecture

Mu-bde-logging relies on four microservices that act as a pipeline in the data collection and discovery process.

* **mu-swarm-logger-service**: observes for events in the docker socket and stores the information in a triplestore database.
* **mu-docker-event-query**: queries the triplestore for started containers with the "logging=true" label activated, and store the data in a JSON file.
* **mu-docker-watcher**: looks for changes in the JSON file generated by the **mu-docker-event-query** microservice, reflecting the addition of new running containers, and runs a new *tcpdump* instance per container to inspect it's network traffic and dump the data in .pcap files.
* **mu-har-transformation**: watches the .pcap files created by the **mu-docker-watcher** microservice and transforms them into .har (json) format, enriching each file with additional data. Also, data is pushed onto an ElasticSearch instance, making it ready to be queried.


## Prerequisites

* Run the **mu-bde-logging** project before any of the containers you wish to log are started. **mu-bde-logging** does not take old events into account.
* For every new started container running with th *"logging=true"* flag, the logging platform will start observing the network traffic it generates.

## Usage

* Copy the *docker-compose.yml* where the containers belonging to a docker network are defined into the root of the project. If you want to observe multiple containers belonging to different networks,
  add the containers that you wish to be added manually to the docker-compose.yml file.
* Run ```docker-compose up```.
* After some traffic has been logged, visit *http://localhost:5601*, and in Kibana specify the index *hars* to start visualizing your data.
